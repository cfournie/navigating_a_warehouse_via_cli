<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta charset="utf-8">
    <style>
      body {
        font-family: 'Roboto';
      }
      h1, h2, h3 {
        font-family: 'Roboto';
        font-weight: bold;
        color: #FFFFFF;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code {
        font-size:0.8em;
      }
      .remark-slide-content {
        background-color: #223274;
        color: #FFFFFF;
        background-size: auto 100%;
        font-size: 2.7em;
        padding: 1em 2em 1em 2em;
      }
      .remark-slide-content h3 {
        font-size: 1em;
      }
      .remark-slide-content h2 {
        font-size: 1.2em;
      }
      .remark-slide-content h1 {
        font-size: 1.5em;
      }      
      .remark-slide-content a {
        color: #FFFFFF;
      }
      .remark-slide-container {
      visibility: hidden;
          display: initial;
      }
      .remark-visible {
          visibility: visible;
      }
      em {
        color: #fb8b8a;
        font-style:normal;
      }
      .statistic {
        font-size: 2em;
        font-weight: bold;
        color: #44bebf;
      }
      .footer {
        position: absolute;
        bottom: 12px;
        left: 20px;
        opacity: .5;
        font-size: 0.55em;
      }
      .remark-slide-number {
        font-size: 0.55em;
      }
      td, th {
        padding: 0 6pt;
      }
    </style>

    <link rel="stylesheet" href="./mermaid.dark.css">
  </head>
  <body>
    <textarea id="source">

layout: true
class: center, middle


<div class="footer"><code>https://github.com/cfournie/navigating_a_warehouse_via_cli</code></div>


---


# Navigating a Data Warehouse via CLI
<br>
<span style="font-size: 0.8em">Chris Fournier (@cfournie)</span>
<br><br><br>
<img src="./shopify_monotone_white.svg" height="70pt" />

???

Hi, I'm Chris Fournier, I work at Shopify, and I'm going to talk to you about some simple scripts we wrote to navigate our data warehouse and the UNIX tools that we combine them with to get the most out of them.

In case you haven't heard of Shopify...


---

background-color: #FFFFFF
background-image: url(./frontpage.png)
background-position: center
background-repeat: no-repeat


???

... we provide a platform for people to sell products online or in person.


---


## Data Warehouse

*Platform* to collect, store, analyze, and report on *data*

???

And the specific team that I work on develops software for and maintains a data warehouse, or a platform used to collect, store, analyze, and report on data collected from our systems.

Our analysts use it to answer questions about the performance of Shopify as a business, our products, and our features.


---


<h3 style="margin: 0.5em 0 0.5em 0">Gross Merchandise Volume</h3>

<img src="./gmv.png" height="440pt" />

???

One example of a question that we try to answer for Shopify as a whole is:

"What is the total value of everything sold through our platform?"

Or Gross Merchandise Volume (GMV).

That's one of the metrics that we use as a company to gauge our success.

This is not a trivial number to calculate given the volume of orders and transactions that we process for our merchants and the number of datasets that we joind this dataset against to be able to break this number down by payment gateway, industry, monthly recurring revenue, etc. In 2016 alone we had over $15 billion dollars worth of GMV and that's a lot of rows. We're also continuously processing data to keep these numbers up to date.

But from a broad techincal perspective, how is this data processed?


Sources:
https://www.slideshare.net/SolmazShahalizadeh/building-a-financial-data-warehouse-a-lesson-in-empathy
https://s2.q4cdn.com/024715446/files/doc_presentations/2017/11/Investor-Deck-Q3-2017.pdf


---
class: center, middle


## Batch jobs

### (E)xtract (T)ransform (L)oad

<div class="mermaid" margin>
graph LR
    A(Extract<br>Orders)-->C(Transform to<br>GMV per Shop)
    B(Extract<br>Transactions)-->C
    C-->D(Load to Database)
</div>

<br><br><br>


???

We predominantly run ETL jobs every few hours that:
  - Extract batches of data from operational systems (like MySQL)
  - Transform that extracted data into a datasets (for example "GMV per shop"), and then
  - Load that into a database for analysts to issue queries against and create reports upon

The batch jobs that we run in our warehouse are written mostly in Python on top of PySpark by our analysts (sometimes with the help of our engineers). The number of these batch jobs, their implementations, and whether a job reads a specific dataset or not changes frequently, making it difficult to keep an up to date picture of how everything works in ones head. How frequently do our jobs change?


---


## Development speed

.center[
<span style="float:left; font-size: 0.9em; width:50%">
<span class="statistic">1100+</span><br>
ETL jobs<br>(as of Nov 1017)
</span>

<span style="float:right; font-size: 0.9em; width:50%">
<span class="statistic">15.2</span><br>
Deploys per day<br>on avg (Â±8.6 std dev)
</span>
]

<br><br><br><br>



???

As of Nov this year we have over 1100+ job implementations, and on average we deploy about 15 different versions of these jobs per day.

The engineering team that I work on not only maintains the platform and frameworks that these jobs run on, but also helps our analysts maintain their jobs and the integrity of the data that they produce.

To help make sure that these jobs are working, and to see which jobs/datasets are affected by bugs that pop up, we need to be able to navigate this ever-changing set of jobs, their implementations, and the relationships between them to debug issues.

How do we do that?


---


background-color: #FFFFFF
background-image: url(./hue_workflow.png)
background-position: center
background-repeat: no-repeat


???

One way that we navigate our jobs is through a Django app called Hue. This isn't the latest version of Hue here, but the UI is essentially the same. It's a very handy way to visualize groups of jobs (which we refer to as flows) and the jobs themselves.


---


background-color: #FFFFFF
background-image: url(./hue_workflows.png)
background-position: center
background-repeat: no-repeat

???

Hue can also show lists of jobs that are completed or being run by our scheduler, Oozie.

One downside to using Hue is that we can't search by all of our job metadata, like where a job reads/writes, which team maintains it, how often it runs, what resources it uses, etc. This is an obstacle when we're trying to explore our jobs, understand how they're related, and break them down by their properties to see if a bug applies to them or not.

So how can we gain access to more metadata to search through?


---

       
### Search YAML schedule definitions


<div style="margin: auto;width: 100%;font-size: 0.85em">
.left[
```yaml
gross-merchandise-volume-flow:
  frequency: 2h
  owner: team@example.com

  compute-gmv-job:
    resource_class: xxlarge
    executable: jobs/compute_gmv.py
    inputs:
      - /data/raw/orders/
      - /data/raw/transactions/
    output: /data/frontroom/gmv-facts/
  
  extract-orders-job:
    ...
```
]
</div>

???

Well, the metadata that we use to schedule our jobs is all contained within YAML files in our git repository alongside the job implementations. These YAML files are at most 20 minutes newer than what's actually running in production, so they're a reliable approximation for the metadata in our scheduler. We can just search these YAML files to learn more about our jobs.

Here's an example of what that YAML looks like. This is the "gross-merchandise-volume-flow" group of jobs that I showed you a graph of earlier, it:
- Runs every 2 hours
- Has a team that owns it
- There's a "compute-gmv-job" job that:
  - Uses a lot of resources
  - Is implemented by a specific Python script
  - Takes "orders" and "transactions" as input, and
  - Outputs a dataset on GMV

There are other jobs that are part of this flow as well, for example the "extract-orders-job", and others not shown for brevity.

Using an editor we can browse this YAML to view metadata, but except for finding details for specific jobs and some basic aggregate statistics (like using your editor's "find" functionality and seeing the number of occurrences of something), there's not a lot of analytical power here, and remember that we have over 1100 jobs that consume each others outputs.

When we find a bug, they usually apply to a set of jobs that all share some similar properties. We need to be able to query our schedule to identify these similar jobs and then find all data that is produced directly or indirectly by them and fix both the jobs and sometimes their data.

YAML has the metadata that we want, but it's not lain out in an easy to consume way.


---


### Tables of metadata

<div style="font-size:0.6em">
.left[
Workflow (group)   | Freq. (h) | Job     | Resources | Etc.
--------------------- | ------------- | ------- | --------- | ---
abiding-poetry        |6  |comp            |small    | ...
abiding-poetry        |6  |defeated  |medium   |
abiding-poetry        |6  |kind-big             |xxlarge  |
abiding-poetry        |6  |load-com       |small    |
abiding-poetry        |6  |load-kind-big        |xlarge   |
abiding-poetry        |6  |swift-energy         |medium   |
confused-indy  |7  |eight         |small    |
confused-indy  |7  |load-eight    |small    |
confused-indy  |7  |load-two-orig    |small    |
confused-indy  |7  |luxury-med     |xlarge   |
]
</div>

<br><br><br>


???

What we really want is to view our job metadata as a table so that we can filter job rows by one or more columns to find the jobs and their datasets affected by a bug.


---


### Parse and print metadata

<div style="margin: auto;width: 100%">
.left[
```python
for flow in flows:
    for job in flow.jobs:
        print('\t'.join((
            flow.name,
            str(flow.frequency),
            job.name,
            job.resource_class.value,
            job.output
        )))
```
]
</div>


???

Thankfully, the YAML files that contain our metadata are contained in the same repository as our Python job implementations and scheduling code, so we thought, let's just script this table!

Let's keep it simple and just read this schedule and print to the console one row of tab-seprated values at a time.

First we iterate over each flow, or group of jobs, and then each job within. Then we print the flow name, frequency that it's scheduled in hours, the job name, resources it uses, and its output.

There's a lot of other metadata that we could print, like the owning team, job implementation file, inputs, etc. but I'm skipping that in this presentation for brevity.

So this will print the information that I just showed you in the previous slide.

Note that I'm printing the flow name and frequency repeatedly, once for each of the flow's jobs. If this were a database table, it would be bad to design a denormalized table like this, but in the terminal, pre joining what could be two tables like this will make filtering jobs by properties that they inherit from flows easier. Denormalized tables are your friend on the CLI.

So, what does this table look like on the CLI?


---


???

```shell
python jobs.py
```

Not bad, but it's a little hard to distinguish the columns. Is there anything that can help us pretty-print this table?

Yes, yes there is, there's a handly little tool called `column` that we can use to format our whitespace for us. All we need to do is generate our output and then pipe it to the column program like so:

```shell
python jobs.py | column -t
```

And look at that, we have a table that we can look at!

But what was that piping wizardry that I just mentioned?

This is some of the magic that UNIX-like operating systems provide that you can use to combine your simple script with many other UNIX tools to create some truly fantastic output.


---


## What is piping?
.left[
```shell
python jobs2.py | column -t
```
]

<div class="mermaid">
graph LR
    A[<em><b>python jobs2.py</b></em><br>stdin=stdin<br>stdout=pipe file]-->C(pipe file)
    C-->D[<em><b>column -t</b></em><br>stdin=pipefile<br>stdout=stdout]
</div>

<span style="font-size:0.5em; opacity:0.5">
https://brandonwamboldt.ca/how-linux-pipes-work-under-the-hood-1518/
</span>

???

Here's the command that I just ran.

Roughly how this works is:
1. Bash creates a special in-memory pipe file in the pipe filesystem
2. Bash then forks twice to create two child processes, one for the python program and one for column program
3. Bash then sets python's stdout (where it writes output to during print) to the write end of the pipe file
4. Bash then sets column's stdin (where it reads input from) to the read end of that same pipe file
5. Both processes run roughly in parrallel and they write and read from the pipe file until they're both finished.

This lets us create a super simple Python script that just creates raw output that we can then pipe to other UNIX programs to massage into our desired form, and the bets part is that we get to spread this work over multiple concurrent processes without writing any threading code ;)

All I've shown you so far though is how to show a table. That's still not very useful for navigating our warehouse of 1100 jobs. What other UNIX tools are available to us and what can we use them for?


---


???

Well, for starters, if we want to throw some columns away, there's a tool called cut. We can use that to take our large table and narrow it down to just the flow name and job name columns:

```shell
python jobs.py | cut -f1 -f2
```

That's still just so-far a display-related tool, what about some real analytics, what about filtering?

How do we answer questions like:

"Which jobs use the large resource class?"

For that we can use a tool called "awk" to filter rows and onlyprint them if they meet certain conditions, such as whether the 4th column contains the string "large".

```shell
python jobs.py | awk '$4 == "large"' | column -t
```

"grep" can also be used for filtering, but when you have variable-sized columns, "awk" is a bit more precise.

Now that we have filtering, what about some aggregate statistics? Can we count? Yes we can, using the worc count program to ask how many lines of filtered output that it sees:

```shell
python jobs.py | awk '$4 == "large"' | wc -l
```

Some of those calls produced a lot of output, and if our table takes a long time to generate output, maybe we want to just peek at a short bit of its output. For that, we can use the "head" tool to just get the first 10 lines of output.

```shell
python broken_jobs.py | head
```

Uh oh!  There's a garbled stack trace in there. What happened?


---


## Piping to `head`

.left[
```shell
python jobs3.py | head
```
]

<div style="margin: auto;width: 100%; font-size: 0.85em">
.left[
```
Traceback (most recent call last):
  File "jobs3.py", line 13, in <module>
    job.output
BrokenPipeError: [Errno 32] Broken pipe
```
]
</div>

???

Getting rid of some of the output we can see that what we got was a `BrokenPipeError`.

That happened because `head` does something special. Head is reading from the pipe file all the output from the python script up until it has decided that it has read enough, in this case after it sees 10 lines, and then it closes the read end of the pipe file.

But our Python script doesn't know that `head` has had enough and it still wants to write more output to the write end of the pipe file.

If the Python script tries to write output to that pipefile and the OS has clsed it, then we get back from the OS an `EPIPE` error which Python wraps for us as a `BrokenPipeError`.

Thankfully though, the OS provides us a way to tell that we should stop writing.


---


## Handling SIGPIPE

<div style="margin: auto;width: 100%;font-size:0.9em">
.left[
```python
import signal

def handle_sigpipe(signum, frame):
    sys.stdout.close()
    sys.exit(0)

signal.signal(signal.SIGPIPE, handle_sigpipe)
```
]
</div>

???

When all file descriptors pointing to the read end of the pipe have been closed, our Python script is sent a signal called SIGPIPE, indicating that the pipe that we were writing to is closed and we should shut down.

All we need to do in our script is write and register a signal handler that closes our write end of the pipe file and exits the program when we receive the SIGPIPE signal.

Now that we've fixed that, what other UNIX tools are there that can help us use these tables to find types of jobs?


---


???

There's a `sort` utility to sort by column which can even interpret text as numbers which we can use to answer:

"What are the most frequently-run jobs?"

```shell
python jobs.py | cut -f1-3 | sort -k2n | head
```


There's also a `uniq` utility that can take a sorted output and filter out duplicates which  we can use to answer:

"Which resource classes are used in the schedule?"

```shell
python jobs.py | cut -f4 | sort | uniq
```

Neat, but how frequently are they used? Uniq has that covered as well, with one flag, we can also ask for counts.

```shell
python jobs.py | cut -f4 | sort | uniq -c
```

Both uniq and sort are useful on their own, but where they really shine is in an application that I'll show you next.


---


<h3 style="margin: 0.25em 0 0.5em 0">Dataset dependencies & paths</h3>

<div class="mermaid">
graph LR
    A(Raw Orders)-->C(GMV per Shop)
    B(Raw Transactions)-->C
    B-->D(Transactions<br>per Shop)
    D-->E(Transactions per Shop<br>& Gateway)
</div>

<div style="margin: auto;font-size:0.6em">
.left[
Start                 | End
--------------------- | --------------
Raw Orders            | GMV per Shop
Raw Transactions      | GMV per Shop
Raw Transactions      | Transactions per Shop
Raw Transactions      | Transactions per Shop & Gateway
Transactions per Shop | Transactions per Shop & Gateway
]
</div>

???

Before I delve into that application though, I want to talk about another type of table that we can generate.

So far we've been filtering a table of jobs, but these jobs have output datasetss and those outputs are often consumed by other "downstream jobs" that produce their own output datasets.

For example, as shown in this graph, "Raw Orders" and "Raw Transactions" datasets feed into the "GMV per Shop" dataset.

In this graph could also say that "Transactions per Shop & Gateway" is downstream of "Raw Transactions" indirectly because there is a path between these two datasets in this directed graph.

Datasets in a data warehouse often depend upon each other like this, and this kind of a graph is useful because we can use it to assess the impact that a mistake in producing one of our datasets would have on our other datasets. For example if we accidentally miss some "Raw Orders", then one other dataset, "GMV per Shop", will also miss those orders.

But if instead the "Raw Transactions" dataset is missing some transactions, then 3 other datasets will be missing data.

We can represent this in a tabular form with one row per path (including those that are subsumed by other paths) and showing just path starts and ends as columns. That generates a lot of rows, but allows us to capture not only direct dependencies, but intirect ones as well, with one for for each.


---


#### What's *downstream* of a *bad dataset*?

<div style="margin: auto;font-size:0.6em">
.left[
Start                 | End
--------------------- | --------------
Raw Orders            | GMV per Shop
Raw Transactions      | GMV per Shop
Raw Transactions      | Transactions per Shop
Raw Transactions      | Transactions per Shop & Gateway
Transactions per Shop | Transactions per Shop & Gateway
]
</div>


<div style="margin: auto;width: 100%;font-size:1em">
.left[
```shell
python downstream.py | awk '$1 == "bad"'
```
]
</div>
<br>


???

From a table of path starts and ends, we could then use `awk` to ask:

"Which datasets are downstream of this bad dataset?"

This would filter all rows (or paths) that have a start equal to the bad dataset, giving us all paths that involve this bad dataset at the start, meaning that each dataset in the end column after this filtering is affected either directly or indirectly by this bad dataset.

Now let's imagine a more alarming scenario than just a single bad dataset poisoning everthing downstream of it. What if we had many bad datasets all at once? What if we first had to figure out which group of our 1100 datasets were bad and then find everything downstream of them?


---


#### What is downstream of this *list* of bad datasets?
<div style="margin: auto;width: 100%;font-size: 1em">
.left[

```shell
python jobs.py
  | awk '$2 < 7 && $4 == "small"'
  > bad

python downstream.py > downstream
```
]
</div>

???

As an example, let's say that we accidentaly added a bug in our software where when we don't have a lot of memory and we run frequently enough our jobs lose data. Let's also say that we've narrowed down the bug to the "small" resource class jobs that run more frequently than 7 hours.

Using "awk" we can filter our table to show just those jobs.

That gives us a list of bad jobs, but to be truly useful, we also need the list of datasets that are downstream of these jobs whose data would bea ffected by these bad jobs. We need the ability to join these two lists together.

Can we do that via the CLI?


---


<h4 style="margin: 0.4em 0 0.4em 0">*`join`* two files</h4>
<div style="margin: auto;width: 50%; font-size:0.9em">
<div style="float: left;width: 40%">
.left[
```
a
b
c
```
]
</div>

<div style="float: right;width: 50%">
.left[
```
a	1
b	2
b	3
d	4
```
]
</div>
</div>

<br><br><br>

<div style="margin: auto;width: 70%; font-size:0.9em">
.left[
```shell
join -1 1 -2 1 file_a file_b
```
]
</div>

<div style="margin: auto;width: 20%;font-size:0.9em">
.left[
```
a 1
b 2
b 3
```
]
</div>


???

Yes, yes we can :D

We can use the `join` command to perform an equality join between two sorted files.  It's very simple and requires that your data is pre-sorted by the column that you want to join on.

It produces one row for each pair of lines that have a matching column in the two files.

For example, we can take these two files at the top here and join them on the first column of each file to produce the result below:

- `a` is in both files, so join emits a row `a 1`, then
- `b` is in both files, so join emits a row `b 2`, then
- `b` is in the second file again, so join also emits a row `b 3`,
- `c` is only in one file so we don't emit a row, and
- `d` is only in one file so we also don't emit a row for it.

If we replace these letters with bad datasets in the first file and the starts and ends of paths between datasets in the second file, then we can join them together to produce a list of all datasets downstream of a bad dataset.

So let's do that!


---


???

First let's get a sorted list of bad datasets:

```shell
python jobs.py | column -t
python jobs.py | awk '$2 < 7 && $4 == "small"'
python jobs.py | awk '$2 < 7 && $4 == "small"' > a
cut -f5 a | sort -k1 > b
column -t b
wc -l b
```

Next, let's get a sorted list of all path starts and ends:

```shell
python downstream.py | head | column -t
python downstream.py | sort -k1 > c
head c
```

Finally, let's join these two datasets together on the first column:
```shell
join -1 1 -2 1 -t $'\t' b c > joined
head joined
```

Now we have a list of every path downstream of that list of bad datasets. What we want though is the bad and downstream datasets merged together get a list of everything that is affected by this issue. To do that we need to convert these paths to datasets by just taking the path ends, combining them with the list of bad datasets, sorting them, and then getting just the unique list at the end:
```shell
cut -f2 joined > d
sort b d | uniq > affected
wc -l affected
wc -l b
python jobs.py | wc -l
```

And there you have it, a way to generate simple metadata tables about jobs on the CLI and then use UNIX tools to filter and join them together to answer real questions about the jobs that run in a data warehouse.


---


## How to trace bad data
<div style="font-size:0.85em">
.left[
1. Filter *metadata tables* for bad jobs
2. Join bad job outputs to *tables of paths*
]
</div>
<br>

???


What I showed you here was an artificial scenario using some very simple scripts to make tables, but all of the principles are the same in the version that we use day to day. We find bad datasets and join them against a list of everthing downstream of them to figure our what needs to be fixed.

This strategy of making tables so that we can filter by job metadata to find jobs that are likely to be affected by a bug has proven invaluable. We've used it to query our jobs to find those that:

- Read and filter Parquet files by time (because we had a bug where we truncated milliseconds while filtering, dropping 2s of data on every read)
- We also searched for jobs that read data from a specific MySQL cluster because we forgot to read from two newly added MySQL shards for a short time; and
- We also looked for jobs that from some Kafka topics because Kafka was errioneiosly configured to mirror to itself and duplicated data (yay infinite data).

Searching for jobs by their metadata to see if a byg applies to them of not does generate false positives, but when tracing bad data, it's better to rebuild a false positive than leave behind a true positive that will continue to provide bad data to downstream jobs.

In all of these situations, being able to come up with an expression to filter our table of jobs and then join against the downstream table saved us countless minutes or even hours mainly because we prepared all of the metadata beforehand and we had a standardized table to parse. Before that, people were trying to write bespoke Python scripts at 3AM to react to an issue and coming up with conflicting results. Now, thanks to these tools, our biggest dissagrement is whether to use `grep` or `awk` for filtering.


---


### UNIX tools for tables
<div style="margin: auto;width: 85%; font-size:0.9em">
.left[
- *`head`* to truncate
- *`column -t`* to pretty-print
- *`grep`* and *`awk`* to filter
- *`wc -l`* to count
- *`sort`* to sort
- *`uniq`* to dedupe / count freqs. (*`-c`*)
- *`join`* to join sorted files
]
</div>
<br>

???

So to summarize, I showed you the benefit of making some simple scripts to output tables and then I showed you how to use them with these wonderful unix tools.

...

And there are so many more that I didn't discuss.

That's all the time that I have unfortunately,


Check out the repo link below if you want these slides or to play around with these scripts, and thanks for listening!


---


## Testing

.left[
- Move script code into modules
- Scripts produce parseable output
]


---


## Performance

.left[
- [`cProfile`](https://docs.python.org/3.6/library/profile.html)
- Use [generators](https://docs.python.org/3/howto/functional.html#generators) (speeds up `head`)
- Use [`pandas`](http://pandas.pydata.org/)
- Make expensive columns flags
  - `--expensive-col`
- cache output (e.g. [`joblib.memory`](https://pythonhosted.org/joblib/memory.html))
]


---


<br>
<br>
## Thanks for listening!
<br>
<img src="./shopify_monotone_white.svg" height="70pt" style="opacity:1" />


    </textarea>
    <link rel="stylesheet" href="tomorrow-night-blue.css">
    <script src="highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="remark.min.js"></script>

    <script src="./mermaid.js"></script>
    <script>mermaid.initialize({
      startOnLoad:true,
      flowchart:{
        htmlLabels:true
      }
    });</script>
    
    <script>
      var slideshow = remark.create({
        // Set the slideshow display ratio
        // Default: '4:3'
        // Alternatives: '16:9', ...
        ratio: '4:3',
        //ratio: '16:9',

      highlightLanguage: 'python',
      highlightStyle: 'tomorrow-night-blue',
      highlightLines: true,
      
        // Navigation options
        navigation: {
          // Enable or disable navigating using scroll
          // Default: true
          // Alternatives: false
          scroll: true,

          // Enable or disable navigation using touch
          // Default: true
          // Alternatives: false
          touch: true,

          // Enable or disable navigation using click
          // Default: false
          // Alternatives: true
          click: false
        },

        // Customize slide number label, either using a format string..
        slideNumberFormat: 'Slide %current% of %total%',
        // .. or by using a format function
        slideNumberFormat: function (current, total) {
          return current + ' of ' + total;
        },

        // Enable or disable counting of incremental slides in the slide counting
        countIncrementalSlides: true
      }); 
    </script>
  </body>
</html>
