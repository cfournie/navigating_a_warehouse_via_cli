<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta charset="utf-8">
    <style>
      body { font-family: 'Roboto'; }
      h1, h2, h3 {
        font-family: 'Roboto';
        font-weight: bold;
        color: #FFFFFF;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-slide-content {
        background-color: #223274;
        color: #FFFFFF;
        background-size: auto 100%;
      }
      .remark-slide-container {
      visibility: hidden;
          display: initial;
      }
      .remark-visible {
          visibility: visible;
      }
      em {
        color: #fb8b8a;
        font-style:normal;
      }
      .statistic {
        font-size: 85pt;
        font-weight: bold;
        color: #44bebf;
      }
      .footer {
        position: absolute;
        bottom: 12px;
        left: 20px;
        opacity: .5;
      }
    </style>

    <link rel="stylesheet" href="./mermaid.dark.css">
  </head>
  <body>
    <textarea id="source">

layout: true
class: center, middle


<div class="footer"><code>https://github.com/cfournie/navigating_a_warehouse_via_cli</code></div>


---


# Navigating a Data Warehouse via CLI

Chris Fournier (@cfournie)

<br/><br/>

<img src="./shopify_monotone_white.svg" width="120pt" />

???

Hi, I'm Chris Fournier and I work at Shopify.

In case you haven't heard of us...


---


background-image: url(./frontpage.png)
background-position: center;
background-repeat: no-repeat;

???

... we provide a platform for people to sell products online or in person.


---


## Data Warehouse

*Platform* to collect, store, analyze, and report on *data*

???

The specific team that I work on develops software for and maintains a data warehouse, or in other words a platform used to collect, store, analyze, and report on data outside of your web app or other operational systems.


Our anaylsts us it to answer questions about the performance of Shopify as a business, our products, and our features.


---


### GMV

<img src="./gmv.png" height="480pt" />

???

One example of a question that we try to answer for Shopify as a whole is:

"What is the total value of everything that has been sold through our platform?"

We call that gross merchandise value (or GMV) and that's one of the metrics that we use as a company to gauge our success.

This is not a trivial number to calculate given the volume of orders and transactions that we process and the analysis that we do to break this number down by payment gateway, industry, monthly recurring revenue, etc. We're also continuously processing data to keep these numbers up to date.

But from a broad techincal perspective, how do we make this dataset?


Sources:
https://www.slideshare.net/SolmazShahalizadeh/building-a-financial-data-warehouse-a-lesson-in-empathy
https://s2.q4cdn.com/024715446/files/doc_presentations/2017/11/Investor-Deck-Q3-2017.pdf


---
class: center, middle


## Batch jobs

### (E)xtract, (T)ransform, and (L)oad

<div class="mermaid">
graph LR
    A(Extract<br>orders)-- raw orders -->C(Transform into<br>GMV per shop)
    B(Extract<br>transactions)-- raw transactions -->C
    C-- GMV per shop -->D(Load to<br>a Database)
</div>

<br><br><br>


???

We predominantly run ETL batch jobs that:
  - Extract batches of data from operational systems (like MySQL) and stores it elsewhere (for example as a dataset called "raw orders")
  - Transform it into a dataset that we can use to answer questions about a specific metric (for example "GMV per shop"), and then
  - Load that dataset into a database for analysts to issue queries against and create reports upon

These batch jobs are written mostly in Python by our analysts (with the help of our engineers).  The number of these batch jobs, their implementations, and whether a job reads a specific dataset or not changes frequently. How frequently?


---


## Development speed

.center[
<span style="float:left;">
<span class="statistic">1100+</span><br>
ETL job implementations<br>(as of Nov 1017)
</span>

<span style="float:right;">
<span class="statistic">15.2</span><br>
Deploys per day in 2017 on<br>average (Â±8.6 std dev)
</span>
]

<br><br><br><br><br><br><br><br><br><br><br>



???

We have over 1100+ job implementations, and so far in 2017 on average we deploy about 15 different versions of these jobs per day.

The engineering team that I work on not only maintains the platform that these jobs are developed and run on, but also helps our analysts keep these jobs running reliably.

To help make sure that these jobs are working, we need to be able to navigate this ever-changing set of jobs, their implementations, and the relationships between them to debug issues.

How do we do that?


---


background-image: url(./hue_workflow.png)
background-position: center;
background-repeat: no-repeat;


???

One way that we navigate our jobs is through a Django app called Hue. It's a very handy way to visualize groups of jobs (which we refer to as flows) and the jobs themselves.


---


background-image: url(./hue_logs.png)
background-position: center;
background-repeat: no-repeat;

???

It can even stream job logs for us.


---


background-image: url(./hue_workflows.png)
background-position: center;
background-repeat: no-repeat;

???

And can also show lists of jobs that are completed or being run by our scheduler, Oozie.

One downside to using Hue is that it was not meant for the number of jobs that we run; its UI renders sluggishly and we can only search by a flow's (or group of jobs) name, and not by any of our job names or metadata (like the where it reads/writes, which team maintains it, etc.).

So how can we get around that?


---

       
### Search YAML flow and job definitions

.left[
```yaml
order-transaction-states-incremental:
  owner: team@example.com
  frequency: 2h
  service-level-objective: 4h

  extract-orders:
    executable: jobs/extract_orders.py
    inputs: ['orders@database']
    output: /data/raw/orders/

  ...

  compute-gmv:
    resource_class: xxlarge
    executable: jobs/compute_gmv.py
    inputs: ['/data/raw/orders/', '/data/raw/transactions/']
    output: /data/frontroom/gmv-facts/

  load-gmv:
    resource_class: xxlarge
    executable: jobs/loader.py
    input: /data/frontroom/gmv-facts/
    output: shopify.gmv_facts@database
```
]

???

Well we store the definition of our schedule in a YAML file in our git repository, and the version that we have in our master branch is at most 20 minutes newer than what could be running in our production environment, so it's a pretty good analogue for production.

We can open the YAML files, look around, for example this is the set of GMV jobs (or the GMV flow) that I showed you earlier: this group of jobs has a team that owns it, it runs every 2h, shouldn't be more than 4h behind, it has an extraction job that produces raw dara, one job that reads that raw data and outputs a dataset describing GMV, and another that loads that GMV dataset into a database.

With this YAML we can use our editor's find tools (or grep) and with some regex we can get some aggregate statistics on our schedule, like how many jobs use "xxlarge" resources or how many jobs do we have in total.

But except for finding details for specific jobs and some basic aggregate statistics, there's not a lot of analytical power here, and remember that we have over 1100 jobs. That's a lot, and when alayzing classes of failures, we'd like to be able to break down that list by various job metadata so that we can better understand which jobs are impacted by an issue.


---


### Format YAML as a table

.left[
Job                     | Resources &nbsp;   | Executable | Etc.
----------------------- | -------------- | -----------
cuddly-two              | large    | jobs/cuddly-two.py | ...
load-cuddly-two         | xxlarge  | jobs/load-cuddly-two.py
untidy-enthusiasm       | small    | jobs/untidy-enthusiasm.py
load-untidy-enthusiasm  | large    | jobs/load-untidy-enthusiasm.py
first-restaurant        | small    | jobs/first-restaurant.py
load-first-restaurant   | small    | jobs/load-first-restaurant.py
jazzy-comfortable       | xxlarge  | jobs/jazzy-comfortable.py
load-jazzy-comfortable  | medium   | jobs/load-jazzy-comfortable.py
annoyed-morning         | xxlarge  | jobs/annoyed-morning.py
ubiquitous-emphasis     | large    | jobs/ubiquitous-emphasis.py
]

<br><br><br>


???

We this YAML data layed out in  a table, and we need the ability to filter by columns.

We can't get that directly from the YAML itself. We also can't get any of properties of the implementations themselves. They're implemented in Python using declarative APIs, and if we instantiated those modules we could learn even more about how they're set up and what they do.

So we can't get this data directly from the YAML, but thankfully we already have libraries that parse this YAML to update our scheduler, Oozie. We have APIs that convert this YAML into XML definitions and Oozie API calls, and we can reuse those APIs and create this table using a Python script!


---


### Parse and print jobs

.left[

```python
flows = lib.generate_schedule()

for flow in flows.values():
    for name, job in flow.jobs.items():
        print(
            name,
            job.resource_class.value,
            job.executable,
            job.inputs,
            job.output
        )
```
]


???

So let's script this! Let's keep it simple and just read this schedule and to compose a table let's just print eveything we know about each job on one line.

What does this look like?

RUN python scripts/jobs1.py

Garbage.


---


## What when wrong?

*Whitespace* was a mess

Jobs have a *variable number of inputs*



???

What went wrong?

Well there was a lot of output.

Whitespace was a mess, we couldn't tell where the columns were.

Jobs also have multiple inputs, so we're basically cramming an array of inputs into one cell in this table. Not great.

So let's try something similar, but this time let's omit inputs and I'll show you one of my favourite commands to help format output on the CLI.

RUN python scripts/jobs2.py | column -t

 
---


## Which jobs use xxlarge resources?

`awk`

---

## Just the names of xxlarge resource jobs

`cut`

---

## Names and implementations

`cut`, `column -t`

---

## Which jobs have no implementation?

`awk` for "NA"


---

## Denormalized data

Show flow and job data together

---


## Dataset graph

---


## Flatten as input, output

---

## Flatten as input, downstream output, depth

---

## Data poisioning uses

Which jobs are downstream of other jobs that are of type X?

List jobs of type X

List dowstream of all jobs

Need to join!

---

## Join

---

## Arbitrary Qs possible

---

## Speed

- Perception of speed (us generators and output each line as generated)
- Profile using cprofile
- Generate cols on demand
- Cache output (invalidate on input changes)

---

## Testing

- Move as much code into your models and unit test there
- Script should produce parseable output; mock its data and parse it
- Integration test against real data (answer a Q that should remain stable)

    </textarea>
    <link rel="stylesheet" href="tomorrow-night-blue.css">
    <script src="highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="remark.min.js"></script>

    <script src="./mermaid.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    
    <script>
      var slideshow = remark.create({
        // Set the slideshow display ratio
        // Default: '4:3'
        // Alternatives: '16:9', ...
        ratio: '4:3',

      highlightLanguage: 'python',
      highlightStyle: 'tomorrow-night-blue',
      highlightLines: true,
      
        // Navigation options
        navigation: {
          // Enable or disable navigating using scroll
          // Default: true
          // Alternatives: false
          scroll: true,

          // Enable or disable navigation using touch
          // Default: true
          // Alternatives: false
          touch: true,

          // Enable or disable navigation using click
          // Default: false
          // Alternatives: true
          click: false
        },

        // Customize slide number label, either using a format string..
        slideNumberFormat: 'Slide %current% of %total%',
        // .. or by using a format function
        slideNumberFormat: function (current, total) {
          return current + ' of ' + total;
        },

        // Enable or disable counting of incremental slides in the slide counting
        countIncrementalSlides: true
      }); 
    </script>
  </body>
</html>
